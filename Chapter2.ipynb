{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/salemprakash/EDA/blob/main/Chapter2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fxg0vHHf-V_u"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3WI93veiD9y4"
   },
   "outputs": [],
   "source": [
    "#The structure of the dataframes is the same in both cases.\n",
    "#In this case, we would need to concatenate them.\n",
    "#We can do that by using the pandas concat() method\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4HGRhL1EIPF"
   },
   "outputs": [],
   "source": [
    "dataFrame1 =  pd.DataFrame({ 'StudentID': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29],\n",
    "                            'Score' : [89, 39, 50, 97, 22, 66, 31, 51, 71, 91, 56, 32, 52, 73, 92]})\n",
    "dataFrame2 =  pd.DataFrame({'StudentID': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30],\n",
    "                            'Score': [98, 93, 44, 77, 69, 56, 31, 53, 78, 93, 56, 77, 33, 56, 27]})\n",
    "\n",
    "# In the dataset above, the first column contains information about student identifier and the second column contains their respective scores in any subject.\n",
    "#The structure of the dataframes is same in the bothe case. In this case, we would need to concatenate both of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhS7jLyfEQ6j"
   },
   "outputs": [],
   "source": [
    "# We can do that by using Pandas concat() method.\n",
    "#Output: A single dataframe combining both of the tables - ignore_index\n",
    "#The ignore_index argument creates a new index\n",
    "dataframe = pd.concat([dataFrame1, dataFrame2], ignore_index=True)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mE4lCe2FQzI"
   },
   "outputs": [],
   "source": [
    "# if we want to combine them side by side\n",
    "pd.concat([dataFrame1, dataFrame2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYaBhV6jX3FC"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0KN_npkERt2"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbyUtJ3QEgXl"
   },
   "outputs": [],
   "source": [
    "df1SE =  pd.DataFrame({ 'StudentID': [9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29],\n",
    "                       'ScoreSE' : [22, 66, 31, 51, 71, 91, 56, 32, 52, 73, 92]})\n",
    "df2SE =  pd.DataFrame({'StudentID': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30],\n",
    "                       'ScoreSE': [98, 93, 44, 77, 69, 56, 31, 53, 78, 93, 56, 77, 33, 56, 27]})\n",
    "\n",
    "df1ML =  pd.DataFrame({ 'StudentID': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29],\n",
    "                       'ScoreML' : [39, 49, 55, 77, 52, 86, 41, 77, 73, 51, 86, 82, 92, 23, 49]})\n",
    "df2ML =  pd.DataFrame({'StudentID': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "                       'ScoreML': [93, 44, 78, 97, 87, 89, 39, 43, 88, 78]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bm27rwM7YHAc"
   },
   "outputs": [],
   "source": [
    "# Option 1\n",
    "dfSE = pd.concat([df1SE, df2SE], ignore_index=True)\n",
    "dfML = pd.concat([df1ML, df2ML], ignore_index=True)\n",
    "\n",
    "df = pd.concat([dfML, dfSE], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14M3YWAfYTsa"
   },
   "outputs": [],
   "source": [
    "# Option 2\n",
    "dfSE = pd.concat([df1SE, df2SE], ignore_index=True)\n",
    "dfML = pd.concat([df1ML, df2ML], ignore_index=True)\n",
    "\n",
    "df = dfSE.merge(dfML, how='inner')\n",
    "df\n",
    "\n",
    "# Here, you will perform inner join with each dataframe. That is to say, if an item exists on the both dataframe, will be included in the new dataframe. This means, we will get the list of students who are appearing in both the courses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3jx5YOzYbK-"
   },
   "outputs": [],
   "source": [
    "# Option 3\n",
    "dfSE = pd.concat([df1SE, df2SE], ignore_index=True)\n",
    "dfML = pd.concat([df1ML, df2ML], ignore_index=True)\n",
    "\n",
    "df = dfSE.merge(dfML, how='left')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qs1DbDc2Yixp"
   },
   "outputs": [],
   "source": [
    "# Option 4\n",
    "dfSE = pd.concat([df1SE, df2SE], ignore_index=True)\n",
    "dfML = pd.concat([df1ML, df2ML], ignore_index=True)\n",
    "\n",
    "df = dfSE.merge(dfML, how='right')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xetDJ4FY82s"
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/salemprakash/EDA/main/Data/sales.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AkLqeLVGZRVB"
   },
   "outputs": [],
   "source": [
    "#@title Default title text\n",
    "#Add new colum that is the total price based on the quantity and the unit price\n",
    "\n",
    "df['TotalPrice'] = df['UnitPrice'] * df['Quantity']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZZXbCgAZs91"
   },
   "outputs": [],
   "source": [
    "df['Company'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6SWO4VeZ73W"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cESs9f97aA0j"
   },
   "source": [
    "#Reshaping with Hierarchical Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2EOcFeWwaCcz"
   },
   "outputs": [],
   "source": [
    "data = np.arange(15).reshape((3,5))\n",
    "indexers = ['Rainfall', 'Humidity', 'Wind']\n",
    "dframe1 = pd.DataFrame(data, index=indexers, columns=['Bergen', 'Oslo', 'Trondheim', 'Stavanger', 'Kristiansand'])\n",
    "dframe1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZTOLUeAaLTV"
   },
   "outputs": [],
   "source": [
    "stacked = dframe1.stack()\n",
    "stacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GliJRKyeaTpy"
   },
   "outputs": [],
   "source": [
    "stacked.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZu7ODgGaaHU"
   },
   "outputs": [],
   "source": [
    "series1 = pd.Series([000, 111, 222, 333], index=['zeros','ones', 'twos', 'threes'])\n",
    "series2 = pd.Series([444, 555, 666], index=['fours', 'fives', 'sixs'])\n",
    "\n",
    "frame2 = pd.concat([series1, series2], keys=['Number1', 'Number2'])\n",
    "frame2.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1lmmDYhaiSq"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbAxR3jtaj8n"
   },
   "outputs": [],
   "source": [
    "#Performing data deduplication\n",
    "#1. Let's consider a simple dataframe, as follows:\n",
    "frame3 = pd.DataFrame({'column 1': ['Looping'] * 3 +\n",
    " ['Functions'] * 4, 'column 2': [10, 10, 22, 23, 23, 24, 24]})\n",
    "frame3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yoldQRaHau2E"
   },
   "outputs": [],
   "source": [
    "#2. The pandas dataframe comes with a duplicated() method that returns a Boolean series stating which of the rows are duplicates:\n",
    "frame3.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxTLNDopa5Vs"
   },
   "outputs": [],
   "source": [
    "#3. Now, we can drop these duplicates using the drop_duplicates() method:\n",
    "frame4 = frame3.drop_duplicates()\n",
    "frame4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wJdCXDka_qc"
   },
   "outputs": [],
   "source": [
    "#4. Let's add a new column and try to find duplicated items based on the second column:\n",
    "frame3['column 3'] = range(7)\n",
    "frame5 = frame3.drop_duplicates(['column 2'])\n",
    "frame5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Note that both the duplicated and drop_duplicates methods keep the first observed value during the duplication removal process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IodeH7pJbDeh"
   },
   "source": [
    "#####2. Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cdyBYVJSRos"
   },
   "outputs": [],
   "source": [
    "#find and replace some values inside a dataframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "replaceFrame = pd.DataFrame({'column 1': [200.00, 3000., -786.,\n",
    "            3000., 234., 444., -786., 332., 3332. ], 'column 2': range(9)})\n",
    "replaceFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GModwpgfSpkC"
   },
   "outputs": [],
   "source": [
    "#Replace -786 as NaN - One replacement at a time\n",
    "replaceFrame.replace(to_replace =-786, value= np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jrTs4-fS_cL"
   },
   "outputs": [],
   "source": [
    "#Two or more replacement. All -786 values will be replaced by NaN and all 0 values will be replaced by 2.\n",
    "replaceFrame = pd.DataFrame({'column 1': [200., 3000., -786.,\n",
    "            3000., 234., 444., -786., 332., 3332. ], 'column 2': range(9)})\n",
    "#All -786 values will be replaced by NaN and all 0 values will be replaced by 2.\n",
    "\n",
    "replaceFrame.replace(to_replace =[-786, 0], value= [np.nan, 2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krdr0-9odb0f"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dsf7dOBcdkQG"
   },
   "outputs": [],
   "source": [
    "#Let's assume we have a dataframe as shown\n",
    "data = np.arange(15, 30).reshape(5, 3)\n",
    "dfx = pd.DataFrame(data, index=['apple', 'banana', 'kiwi',\n",
    "'grapes', 'mango'], columns=['store1', 'store2', 'store3'])\n",
    "dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AqOFg5rhAwW"
   },
   "outputs": [],
   "source": [
    "#Let's add some missing values to our dataframe:\n",
    "dfx['store4'] = np.nan\n",
    "dfx.loc['watermelon'] = np.arange(15, 19)\n",
    "dfx.loc['oranges'] = np.nan\n",
    "dfx['store5'] = np.nan\n",
    "dfx['store4']['apple'] = 20.\n",
    "dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UA04TNurhaWm"
   },
   "outputs": [],
   "source": [
    "#Note the following characteristics of missing values in the preceding dataframe:\n",
    "#An entire row can contain NaN values.\n",
    "#An entire column can contain NaN values.\n",
    "#Some (but not necessarily all) values in both a row and a column can be NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ow6UO5jzhrw4"
   },
   "outputs": [],
   "source": [
    "#NaN values in pandas objects\n",
    "#1. Check the following example:\n",
    "dfx.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NO5Nl18qh5Ac"
   },
   "outputs": [],
   "source": [
    "#2. Check it out in action:\n",
    "dfx.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ivtjGHM5iT92"
   },
   "outputs": [],
   "source": [
    "#3. We can use the sum() method to count the number of NaN values in each store.\n",
    "dfx.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y027vxvyikxC"
   },
   "outputs": [],
   "source": [
    "#4. We can go one level deeper to find the total number of missing values\n",
    "dfx.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUFIzI1VjCK6"
   },
   "outputs": [],
   "source": [
    "#5. So, instead of counting the number of missing values, we can count the number of reported values:\n",
    "dfx.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Su2dVqtkjiQJ"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuujD_cAjh06"
   },
   "outputs": [],
   "source": [
    "dfx.store4[dfx.store4.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vf10ahbOkl2R"
   },
   "outputs": [],
   "source": [
    "#The output shows that store4 only reported two items of data. Now, we can use the dropna() method to remove the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixz9Yf18kody"
   },
   "outputs": [],
   "source": [
    "dfx.store4.dropna()\n",
    "\n",
    "\n",
    "#Note that the dropna() method just returns a copy of the dataframe by dropping the rows with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Au2ToEORlDiP"
   },
   "outputs": [],
   "source": [
    "#If dropna() is applied to the entire dataframe, then it will drop all the rows from the dataframe, because there is at least one NaN value in our dataframe:\n",
    "dfx.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzZy_NQCl0Lz"
   },
   "outputs": [],
   "source": [
    "#####Dropping by rows\n",
    "#We can also drop rows that have NaN values. To do so, we can use the how=all argument to drop only those rows entire values are entirely NaN:\n",
    "dfx.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlBLAzaymK3j"
   },
   "outputs": [],
   "source": [
    "#Dropping by columns\n",
    "#Furthermore, we can also pass axis=1 to indicate a check for NaN by columns.\n",
    "dfx.dropna(how='all', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wl9ZgysWmeyy"
   },
   "outputs": [],
   "source": [
    "#we can also pass another argument, thresh, to specify a minimum number of NaNs that must exist before the column should be dropped:\n",
    "dfx.dropna(thresh=5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6OJ1Q4Sod42"
   },
   "outputs": [],
   "source": [
    "#Mathematical operations with NaN\n",
    "ar1 = np.array([100, 200, np.nan, 300])\n",
    "ser1 = pd.Series(ar1)\n",
    "ar1.mean(), ser1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-jYNXBmH5Z0"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsiGSiMUIdAi"
   },
   "outputs": [],
   "source": [
    "#Let's compute the total quantity of fruits sold by store4:\n",
    "ser2 = dfx.store4\n",
    "ser2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEeYsImYInnu"
   },
   "outputs": [],
   "source": [
    "#Average\n",
    "ser2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEoim-mZIpUh"
   },
   "outputs": [],
   "source": [
    "#Cumulative Summing\n",
    "ser2.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4L9RmJZlI9xT"
   },
   "source": [
    "#####5.Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VlU70fcMJJvk"
   },
   "outputs": [],
   "source": [
    "#We can use the fillna() method to replace NaN values with any particular values.\n",
    "filledDf = dfx.fillna(0)\n",
    "filledDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93Z-PvnwJaPK"
   },
   "outputs": [],
   "source": [
    "#Check the difference in the following between NaN and NA filling\n",
    "dfx.mean()\n",
    "filledDf.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QvoltE-CJmWn"
   },
   "outputs": [],
   "source": [
    "#Backward and forward filling\n",
    "#forward-filling - method = ffill\n",
    "dfx.store4.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Hx81WHIKOOj"
   },
   "outputs": [],
   "source": [
    "#backwad-filling -method =bfill\n",
    "dfx.store4.fillna(method='bfill')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
